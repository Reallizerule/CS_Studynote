#无监督学习
  利用无标签的数据学习数据的分布或数据与数据之间的关系，被称作无监督学习
  #有监督学习和无监督学习最大区别是数据是否有标签
  #无监督学习常用于聚类和降维任务


#聚类：根据数据的‘相似程度’将数据分为多类的过程
    评估两个不同样本间的相似性，通常使用的方法是计算两个样本之间的
    距离，使用不同的方法计算样本的距离会关系到聚类结果的好坏
    #常用距离计算方法
     欧氏距离：欧式空间两点之间的直线距离。sqrt((x1-x2)^2+(y1-y2)^2)
     曼哈顿距离：类似城市中驾车，从一个十字路口另一个十字路口的距离（不能斜）。d=|x1-x2|+|y1-y2|
     马氏距离：表示数据的协方差距离，与尺度无关。会先将样本点各个属性标准化，再计算样本点距离
                d(x1,x2)=sqrt((x1-x2)^TS^-1*(x1-x2),s是协方差矩阵
     夹角余弦：用空间中两个向量夹角的余弦值来衡量样本差异的大小，夹角越接近0，越相似
                              
                                                                    

#sklearn中 聚类算法包含在sklearn.cluster模块中
     聚类算法函数可以用不同的数据形式作为输入
        标准数据输入格式为[样本个数，特征个数]定义的矩阵形式
     DBSKAN和近邻传播算法也可以接受相似性矩阵的输入格式
        如余弦相似度，对角线全为1，每个元素取值范围[0,1]
                              
算法名称      参数       可拓展性     相似性度量
                            
k-means      聚类个数     大规模数据     点间距离                        

DBSCAN       领域大小     大规模数据     点间距离

Gaussian     聚类个数及超参  复杂度高，不适合大规模   马氏距离

Birch       分支因子，阀值，超参  大规模数据   两点的欧氏距离


#降维： 保证数据具有代表性特性或者分布的情况下，将高维数据转化为低维数据
        数据的可视化。精简数据
      （ 如4维的鸢尾花数据，PCA变换后在二维的空间展示）
降维算法：可以理解为对数据集组成的成分进行分析）调用sklearn.decompositioin
     
算法名称      参数         可拓展性      适用任务
PCA      所降维度与超参    大规模数据    信号处理
FastICA  所降维度与超参    超大规模数据   图像特征提取
NMF      所降维度与超参    大规模数据    图像特征提取
LDA      所降维度与超参    大规模数据     文本数据，主体挖掘                   
#分类和降维都是无监督学习的典型任务，任务之间存在关联
  某些高维数据的分类可以通过降维处理获得，且k-means和降维算法NMF存在等价性
                              

                              
